{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get W2 and B2 on Train Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 80)\n",
      "(80,)\n"
     ]
    }
   ],
   "source": [
    "# Get the training data\n",
    "data_train = np.loadtxt('iristrain-1.csv', delimiter=',', skiprows=1)\n",
    "X_Train, Y_Train = np.array(data_train[:, 0:4]), np.array(data_train[:, 4])\n",
    "\n",
    "X_Train = np.transpose(X_Train)\n",
    "Y_Train = np.transpose(Y_Train)\n",
    "\n",
    "print(X_Train.shape)\n",
    "print(Y_Train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0: \n",
      " [[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "W1: \n",
      " [[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "W2: \n",
      " [[1. 1. 1. 1.]]\n",
      "B0: \n",
      " 0\n",
      "B1: \n",
      " 0\n",
      "B2: \n",
      " 1\n"
     ]
    }
   ],
   "source": [
    "# number of training examples\n",
    "m = 80\n",
    "\n",
    "# number of features\n",
    "n = 4\n",
    "\n",
    "W0 = np.eye(n)\n",
    "W1 = W0\n",
    "B0 = 0\n",
    "B1 = 0\n",
    "W2 = np.ones((1, n))\n",
    "B2 = 1\n",
    "\n",
    "print(\"W0: \\n\", W0)\n",
    "print(\"W1: \\n\", W1)\n",
    "print(\"W2: \\n\", W2)\n",
    "print(\"B0: \\n\", B0)\n",
    "print(\"B1: \\n\", B1)\n",
    "print(\"B2: \\n\", B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_act(yhat):\n",
    "    return yhat\n",
    "\n",
    "def tanh_act(yhat):\n",
    "    return (np.exp(yhat) - np.exp(-yhat)) / (np.exp(yhat) + np.exp(-yhat))\n",
    "\n",
    "def sigmoid(yhat):\n",
    "    return 1 / (1 + np.exp(-yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2: \n",
      " [[-1.37203655 -3.55865762  5.82179189  3.3445902 ]]\n",
      "B2: \n",
      " 0.08939373624452765\n"
     ]
    }
   ],
   "source": [
    "# X = training data read from the file\n",
    "# for h in range(g):\n",
    "#   X0 = X         # Assign input vector to the input of Layer 0 (unit activation)       \n",
    "#   G0 = W0 X0 + B0 # Determine G0   \n",
    "#   H0 = f0(G0)    # Apply activation function of Layer 0\n",
    "#   X1 = H0\n",
    "#   G1 = W1 X1 + B1 # Determine G1   \n",
    "#   H1 = f1(G1)    # Apply activation function of Layer 1 (unit activation)\n",
    "#   X2 = H1\n",
    "#   G2 = W2 X2 + B2 # Determine G2   \n",
    "#   H2 = f2(G2)    # Apply activation function of Layer 2 (sigmoid activation)\n",
    "\n",
    "#  J[0,h] = ...... # Determine cost function\n",
    "#  # Determine derivatives using the code from past Logistic Regression assignment\n",
    "#  # Use update formula to update W2 and B2\n",
    "#  # Loop\n",
    "# print(W2 and B2) \n",
    "\n",
    "alpha = 0.05\n",
    "g = 100000\n",
    "J = np.zeros(g).reshape(1,g)\n",
    "\n",
    "for h in range(g):\n",
    "    X0 = X_Train\n",
    "    G0 = np.matmul(W0, X0)\n",
    "    H0 = identity_act(G0) # Layer 0 Activation\n",
    "    X1 = H0\n",
    "\n",
    "    G1 = np.matmul(W1,X1) + B1\n",
    "    H1 = identity_act(G1) # Layer 1 Activation\n",
    "    X2 = H1\n",
    "\n",
    "    G2 = np.matmul(W2,X2) + B2\n",
    "    H2 = sigmoid(G2) # Layer 2 Activation\n",
    "\n",
    "    Y_hat = H2\n",
    "    J[0, h] = -1 / m * (np.matmul(np.transpose(Y_Train),\n",
    "                                  np.transpose(np.log(Y_hat))) + np.matmul(np.transpose(\n",
    "        (1 - Y_Train)), np.transpose(np.log(1 - Y_hat))))\n",
    "    dJdz = Y_hat - Y_Train\n",
    "    dJdb = np.sum(dJdz) / m\n",
    "    dJdw = 1/m*np.matmul(dJdz, np.transpose(X_Train))\n",
    "    W2 = W2 - (alpha * dJdw)\n",
    "    B2 = B2 - (alpha * dJdb)\n",
    "#     W1 = W1 - (alpha*dJdw)\n",
    "#     B1 = B1 - (alpha*dJdb)\n",
    "\n",
    "\n",
    "# print(dJdw)\n",
    "# print(Y_hat.shape)\n",
    "# print(W2.shape)\n",
    "# print(J)\n",
    "#     J[0,h] = -1/m*np.sum(Y_Train[h]*np.log(Y_hat)+(1-Y_Train[h])*np.log(1-Y_hat))\n",
    "#     dJdz = Y_hat - Y_Train[h]\n",
    "#     dJdb = np.sum(dJdz)/m\n",
    "#     dJdw = 1/m*np.matmul(dJdz, X_Train)\n",
    "\n",
    "print(\"W2: \\n\", W2)\n",
    "print(\"B2: \\n\", B2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get W2 and B2 on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = np.loadtxt('iristest-1.csv', delimiter=',', skiprows=1)\n",
    "X_Test, Y_Test = np.array(data_train[:, 0:4]), np.array(data_train[:, 4])\n",
    "X_Test, Y_Test = np.transpose(X_Test), np.transpose(Y_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0: \n",
      " [[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "W1: \n",
      " [[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "W2: \n",
      " [[1. 1. 1. 1.]]\n",
      "B0: \n",
      " 0\n",
      "B1: \n",
      " 0\n",
      "B2: \n",
      " 1\n"
     ]
    }
   ],
   "source": [
    "# number of training examples\n",
    "m = 20\n",
    "\n",
    "# number of features\n",
    "n = 4\n",
    "\n",
    "W0 = np.eye(n)\n",
    "W1 = W0\n",
    "B0 = 0\n",
    "B1 = 0\n",
    "W2 = np.ones((1, n))\n",
    "B2 = 1\n",
    "\n",
    "print(\"W0: \\n\", W0)\n",
    "print(\"W1: \\n\", W1)\n",
    "print(\"W2: \\n\", W2)\n",
    "print(\"B0: \\n\", B0)\n",
    "print(\"B1: \\n\", B1)\n",
    "print(\"B2: \\n\", B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2: \n",
      " [[-1.54238344 -4.09501682  6.71390778  3.80441623]]\n",
      "B2: \n",
      " -0.016293016705795173\n"
     ]
    }
   ],
   "source": [
    "# X = training data read from the file\n",
    "# for h in range(g):\n",
    "#   X0 = X         # Assign input vector to the input of Layer 0 (unit activation)       \n",
    "#   G0 = W0 X0 + B0 # Determine G0   \n",
    "#   H0 = f0(G0)    # Apply activation function of Layer 0\n",
    "#   X1 = H0\n",
    "#   G1 = W1 X1 + B1 # Determine G1   \n",
    "#   H1 = f1(G1)    # Apply activation function of Layer 1 (unit activation)\n",
    "#   X2 = H1\n",
    "#   G2 = W2 X2 + B2 # Determine G2   \n",
    "#   H2 = f2(G2)    # Apply activation function of Layer 2 (sigmoid activation)\n",
    "\n",
    "#  J[0,h] = ...... # Determine cost function\n",
    "#  # Determine derivatives using the code from past Logistic Regression assignment\n",
    "#  # Use update formula to update W2 and B2\n",
    "#  # Loop\n",
    "# print(W2 and B2) \n",
    "\n",
    "alpha = 0.05\n",
    "g = 100000\n",
    "J = np.zeros(g).reshape(1, g)\n",
    "\n",
    "for h in range(g):\n",
    "    X0 = X_Test\n",
    "    G0 = np.matmul(W0, X0) + B0\n",
    "    H0 = identity_act(G0) # Layer 0 Activation\n",
    "    X1 = H0\n",
    "\n",
    "    G1 = np.matmul(W1, X1) + B1\n",
    "    H1 = identity_act(G1) # Layer 1 Activation\n",
    "    X2 = H1\n",
    "\n",
    "    G2 = np.matmul(W2, X2) + B2\n",
    "    H2 = sigmoid(G2) # Layer 2 Activation\n",
    "\n",
    "    Y_hat = H2\n",
    "    J[0,h] = -1 / m * (np.matmul(np.transpose(Y_Test), np.transpose(np.log(Y_hat)))\n",
    "                    + np.matmul(np.transpose(\n",
    "                        (1 - Y_Test)), np.transpose(np.log(1 - Y_hat))))\n",
    "    dJdz = Y_hat - Y_Train\n",
    "    dJdb = np.sum(dJdz) / m\n",
    "    dJdw = 1 / m * np.matmul(dJdz, np.transpose(X_Test))\n",
    "    W2 = W2 - (alpha * dJdw)\n",
    "    B2 = B2 - (alpha * dJdb)\n",
    "\n",
    "print(\"W2: \\n\", W2)\n",
    "print(\"B2: \\n\", B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
